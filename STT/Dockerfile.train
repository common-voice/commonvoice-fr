# Build KenLM 
FROM nvcr.io/nvidia/tensorflow:20.06-tf1-py3 AS kenlm-build

ENV DEBIAN_FRONTEND=noninteractive

RUN apt-get update && \
  apt-get install -y --no-install-recommends \
  build-essential cmake libboost-system-dev \
  libboost-thread-dev libboost-program-options-dev \
  libboost-test-dev libeigen3-dev zlib1g-dev \
  libbz2-dev liblzma-dev && \
  rm -rf /var/lib/apt/lists/*

# Build KenLM to generate new scorers
WORKDIR /code
COPY STT/kenlm /code/kenlm
RUN cd /code/kenlm && \
  mkdir -p build && \
  cd build && \
  cmake .. && \
  make -j $(nproc) || \
  ( echo "ERROR: Failed to build KenLM."; \
  echo "ERROR: Make sure you update the kenlm submodule on host before building this Dockerfile."; \
  echo "ERROR: $ cd STT; git submodule update --init kenlm"; \
  exit 1; )

# Build output graph convertion tool for inference
FROM ubuntu:20.04 AS wget-binaries
ENV DEBIAN_FRONTEND=noninteractive

RUN apt-get update && \
  apt-get install -y --no-install-recommends wget unzip xz-utils && \
  rm -rf /var/lib/apt/lists/*

# Tool to convert output graph for inference
RUN wget --no-check-certificate https://github.com/coqui-ai/STT/releases/download/v0.9.3/convert_graphdef_memmapped_format.linux.amd64.zip -O temp.zip && \
  unzip temp.zip && \
  rm temp.zip

RUN wget --no-check-certificate https://github.com/reuben/STT/releases/download/v0.10.0-alpha.1/native_client.tar.xz -O temp.tar.xz && \
  tar -xf temp.tar.xz && \
  rm temp.tar.xz

# Build STT
FROM nvcr.io/nvidia/tensorflow:20.06-tf1-py3

# Import Args in Env
ARG cc_repo=mozilla/CorporaCreator
ARG cc_sha1=73622cf8399f8e634aee2f0e76dacc879226e3ac

# Model parameters
ARG model_language=fr
ENV MODEL_LANGUAGE=$model_language

# Training hyper-parameters
ARG batch_size=64
ENV BATCH_SIZE=$batch_size

ARG n_hidden=2048
ENV N_HIDDEN=$n_hidden

ARG epochs=30
ENV EPOCHS=$epochs

ARG learning_rate=0.0001
ENV LEARNING_RATE=$learning_rate

ARG dropout=0.3
ENV DROPOUT=$dropout

ARG lm_top_k=500000
ENV LM_TOP_K=500000

ARG lm_alpha=0.0
ENV LM_ALPHA=$lm_alpha

ARG lm_beta=0.0
ENV LM_BETA=$lm_beta

ARG beam_width=500
ENV BEAM_WIDTH=$beam_width

ARG early_stop=1
ENV EARLY_STOP=$early_stop

ARG amp=0
ENV AMP=$amp

# Dataset management
ARG duplicate_sentence_count=1
ENV DUPLICATE_SENTENCE_COUNT=$duplicate_sentence_count

# Should be of the form: lm_alpha_max,lm_beta_max,n_trials
ARG lm_evaluate_range=
ENV LM_EVALUATE_RANGE=$lm_evaluate_range

# Others
ARG english_compatible=0
ENV ENGLISH_COMPATIBLE=$english_compatible

ARG uid=999
ENV UID=$uid

ARG gid=999
ENV GID=$gid

# Make sure we can extract filenames with UTF-8 chars
ENV LANG=C.UTF-8

# Avoid keyboard-configuration step
ENV DEBIAN_FRONTEND noninteractive

ENV HOMEDIR /home/code

ENV VIRTUAL_ENV_NAME stt-train
ENV VIRTUAL_ENV $HOMEDIR/$VIRTUAL_ENV_NAME
ENV STT_DIR $HOMEDIR/stt
ENV CC_DIR $HOMEDIR/cc

ENV PATH="$VIRTUAL_ENV/bin:$PATH"

RUN env

# We need to purge python3-xdg because
# it's breaking STT install later with
# errors about setuptools
RUN apt-get update && \
  apt-get install -y --no-install-recommends \
    git \
    wget \
    libopus0 \
    libopusfile0 \
    libsndfile1 \
    sox \
    libsox-fmt-mp3 \
    libmagic-dev && \
  apt-get purge -y python3-xdg && \
  rm -rf /var/lib/apt/lists/*

# Make sure pip and its dependencies are up-to-date
RUN pip3 install --upgrade pip wheel setuptools

# # Creating user for security purposes
# RUN groupadd -g $GID trainer && \
#   adduser --system --uid $UID --group trainer

# RUN echo "trainer ALL=(root) NOPASSWD:ALL" > /etc/sudoers.d/trainer && \
#   chmod 0440 /etc/sudoers.d/trainer

# # Below that point, nothing requires being root
# USER trainer

# Corpus creator
WORKDIR $HOMEDIR

RUN git clone https://github.com/$cc_repo.git $CC_DIR

WORKDIR $CC_DIR

RUN git checkout $cc_sha1

WORKDIR $CC_DIR

# Copy copora patch
COPY corpora.patch $CC_DIR

RUN patch -p1 < corpora.patch

# error: parso 0.7.0 is installed but parso<0.9.0,>=0.8.0 is required by {'jedi'}
RUN pip install parso==0.8.3

RUN pip install modin[all]

RUN python setup.py install

# For CC PMF importer
RUN pip install num2words

WORKDIR $HOMEDIR

ENV PATH="${STT_DIR}/kenlm/build/bin/:$PATH"

# Copy now so that docker build can leverage caches
COPY . ${HOMEDIR}/

RUN true

COPY ${MODEL_LANGUAGE}/ ${HOMEDIR}/${MODEL_LANGUAGE}/

RUN true

COPY STT ${STT_DIR}

COPY STT/native_client ${STT_DIR}/native_client

RUN true

COPY STT/.git ${STT_DIR}/.git

RUN true

COPY STT/training/coqui_stt_training/VERSION ${STT_DIR}/training/coqui_stt_training/VERSION

RUN true

COPY STT/training/coqui_stt_training/GRAPH_VERSION ${STT_DIR}/training/coqui_stt_training/GRAPH_VERSION

# Build CTC decoder first, to avoid clashes on incompatible versions upgrades
RUN cd STT/native_client/ctcdecode && make NUM_PROCESSES=$(nproc) bindings
RUN pip3 install --upgrade ${STT_DIR}/native_client/ctcdecode/dist/*.whl

COPY STT/setup.py ${STT_DIR}/setup.py

RUN true

COPY STT/VERSION ${STT_DIR}/VERSION

RUN true

COPY STT/training ${STT_DIR}/training
# Copy files from previous build stages
RUN mkdir -p ${STT_DIR}/kenlm/build/
COPY --from=kenlm-build ${STT_DIR}/kenlm/build/bin ${STT_DIR}/kenlm/build/bin

RUN true

COPY --from=wget-binaries /convert_graphdef_memmapped_format ${STT_DIR}/convert_graphdef_memmapped_format

RUN true

COPY --from=wget-binaries /generate_scorer_package ${STT_DIR}/generate_scorer_package

ENTRYPOINT "$HOMEDIR/run.sh"
